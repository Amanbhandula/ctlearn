Logging:
    # Required string.
    # Path to directory to store TensorFlow model checkpoints and summaries.
    # A timestamped copy of the configuration file will also be put here.
    model_directory: '/tmp/logs/example/'

Data:
    # Required string. 
    # Valid options:
    #   - 'HDF5': ImageExtractor v0.5.1 HDF5 format
    # Data file format. Used to choose the right DataLoader subclass.
    format: HDF5

    # Required string.
    # Path to a file listing data file paths, one per line.
    file_list: '/tmp/dataset/file_list.txt'

    # Optional Boolean. Default: true
    # Whether to apply processing to loaded data. If False, no DataProcessor
    # is instantiated and Data:Processing settings are not used.
    apply_processing: true
    
    # Settings for instantiating the DataLoader.
    Loading:
        # Optional string. Default: 'array'
        # Valid options:
        #   - 'array': Examples are all images of a telescope type per event
        #   - 'single_tel': Examples are single telescope images
        # How to construct examples from the data.
        example_type: 'array'

        # Optional string. Default: 'LST'
        # Valid options:
        #   - 'LST': LST Telescope and Camera
        #   - 'MSTF': MST Telescope with FlashCAM Camera
        #   - 'MSTN': MST Telescope with NectarCAM Camera
        #   - 'MSTS': SCT Telescope and Camera
        #   - 'SST1': SST-1M Telescope with DigiCam Camera
        #   - 'SSTA': SST-2M ASTRI Telescope and Camera
        #   - 'SSTC': SST-2M GCT Telescope with CHEC Camera
        #   - 'VTS': VERITAS Telescope and Camera
        # Telescope type to load.
        selected_tel_type: 'LST'
        
        # Optional list of integers. Default: load all telescopes of the
        # selected tel type.
        # ID numbers of telescopes to load of the selected tel type.
        selected_tel_ids: [1, 2, 3, 4]

        # Optional integer. Default: 1
        # Minimum number of triggered telescopes of the selected type which
        # must be present for an event to be loaded.
        min_num_tels: 1

        # Optional string. Default: don't apply any cuts.
        # PyTables cut condition to apply selection cuts to events.
        # See https://www.pytables.org/usersguide/condition_syntax.html
        # for explanation of syntax. Use ViTables http://vitables.org/ to
        # examine HDF5 files to see valid attribute names.
        cut_condition: '(mc_energy > 1.0) & (h_first_int < 20000)'

        # Optional float. Default: 0.1
        # Randomly chosen fraction of data to set aside for validation. 
        validation_split: 0.1

        # Optional integer. Default: use default random initialization.
        # Seed for randomly splitting data into training and validation sets.
        seed: 1234
    
    # Settings for instantiating the DataProcessor.
    Processing:
        # Optional Boolean. Default: false
        # Whether to crop each telescope image by cleaning the image,
        # calculating a bounding box about the cleaned image centroid, and
        # returning the original or cleaned image cropped about the box.
        crop: false

        # Optional string or null. Default: 'twolevel'
        # Valid options:
        #   - 'twolevel': Use two-level cleaning algorithm
        #   - null: Don't apply any cleaning
        # When cropping, type of image cleaning to apply when calculating
        # the weighted centroid position of each telescope image.
        image_cleaning: 'twolevel'

        # Optional Boolean. Default: false
        # When cropping, whether to return the cleaned instead of original
        # cropped images.
        return_cleaned_images: false
       
        # Optional dictionary with string keys and integer values.
        # See Data:Loading:selected_tel_type for valid keys.
        # Default:
        #   MSTS: 48
        # When cropping, side length of the square cropped image.
        bounding_box_sizes:
            MSTS: 48
             
        # Optional dictionary with string keys and list of two integers values.
        # See Data:Loading:selected_tel_type for valid keys.
        # Default:
        #   MSTS: [5.5, 1.0]
        # When cropping and using two level cleaning method, cleaning
        # thresholds to use. The first value is the picture threshold,
        # which passes all pixels in the image greater than it, and the
        # second is the boundary threshold, which adds all pixels greater
        # than it and adjacent to previously selected pixels.
        thresholds:
            MSTS: 
                - 5.5
                - 1.0

        # Optional string or null. Default: null
        # Valid options:
        #   - 'log': Log-normalize by subtracting from each pixel the minimum
        #       value from all selected images, then taking the natural log
        #   - null: Don't apply any normalization
        # Normalization method to be applied pixel-wise to each image.
        normalization: null

        # Optional string or null. Default: null
        # Valid options:
        #   - 'trigger': Order by all triggered followed by all blank images
        #   - 'size': Order by largest to smallest total sum of pixel values
        #   - null: Keep DataLoader ordering (by telescope ID)
        # How to sort telescope images when loading data in array mode.
        sort_images_by: null
   
    # Settings for the TensorFlow Estimator input function.
    Input:
        # Required integer.
        # Number of examples per batch for training/prediction.
        batch_size: 64

        # Required Boolean.
        # Whether to prefetch examples in the TensorFlow Dataset.
        prefetch: true
    
        # Required integer.
        # If prefetching, maximum number of examples to prefetch and store
        # in buffer.
        prefetch_buffer_size: 10

        # Required Boolean.
        # Whether to apply Dataset.map(). Must be true for HDF5 data.
        map: true

        # Required integer.
        # Number of parallel threads to use when loading examples.
        num_parallel_calls: 1

        # Required Boolean.
        # Whether to shuffle examples when creating the TensorFlow Dataset.
        shuffle: true
        
        # Required integer.
        # Number of examples to shuffle at once. Larger buffer sizes
        # give a more uniform shuffle at the cost of a longer time to shuffle.
        shuffle_buffer_size: 10000

# Settings for mapping 1D pixel vectors to 2D images.
Image Mapping:
    # Optional string. Default: 'oversampling'
    # Valid options:
    #   - 'oversampling': Convert each each hexagonal pixel to four square
    #       pixels and reweight the charge to realign to a square grid
    # Algorithm to convert images with hexagonal pixel grids to square grids
    hex_conversion_algorithm: 'oversampling'

    # Optional dictionary with string keys and integer values.
    # See Data:Loading:selected_tel_type for valid keys.
    # Default: 0 for every valid key.
    # Number of pixels of padding to add around the edge of the mapped image.
    # A value of 1 will increase both the image height and width by 2, etc.
    padding:
        - 'LST': 2
        - 'MSTF': 1
        - 'MSTN': 2
        - 'MSTS': 4
        - 'SST1': 1
        - 'SSTA': 0
        - 'SSTC': 0
        - 'VTS': 1

# Settings related to the model (mostly user-defined)
Model:

    # Required string.
    # Path to directory containing model module.
    model_directory: '/home/models/'

    # Required string.
    # Module in ModelDirectory containing function implementing model.
    # Modules included with CTLearn:
    #   - 'single_tel': single tel model using a basic convolutional neural
    #       network (CNN)
    #   - 'cnn_rnn': array model feeding output of a basic CNN for each 
    #       telescope into a recurrent neural network (RNN)
    #   - 'variable_input_model': array model feeding combined outputs of a
    #       CNN for each telescope into a CNN network head
    model_module: 'cnn_rnn'

    # Required string.
    # Function in model_module implementing model.
    # Models included with CTLearn:
    #   - 'single_tel':
    #       - 'single_tel_model'
    #   - 'cnn_rnn':
    #       - 'cnn_rnn_model'
    #   - 'variable_input_model':
    #       - 'variable_input_model'
    model_function: 'cnn_rnn_model'
    
    # Additional user-determined custom model parameters
    Model Parameters:
        # Single Tel must specify Network.
        # Network to be used for image classification. The only supported verified 
        # function is "basic_conv_block" within the "basic" module.
        NetworkModule: basic
        NetworkFunction: basic_conv_block

        # CNN-RNN and Variable Input Model must specify CNNBlock.
        # Network to be used for single telescope blocks. The only supported, verified
        # function is "basic_conv_block" within the "basic" module.
        CNNBlockModule: basic
        CNNBlockFunction: basic_conv_block

        # Variable Input Model must specify TelescopeCombination. Supported options are
        # "vector" and "feature_maps". Use "vector" for network heads expected input as
        # a single feature vector and "feature_maps" for those expecting input as a 
        # stack of feature maps as used for convolutional layers.
        TelescopeCombination: feature_maps

        # Variable Input Model must specify NetworkHead.
        # Network to be for array-level processing on the combined telescope outputs.
        # The supported functions are "basic_conv_head" and "basic_fc_head" within
        # the "basic" module.
        NetworkHeadModule: basic
        NetworkHeadFunction: basic_conv_head

        # Model configuration for Basic Conv Block model.
        # Pipe-separated string. Filters for each CNN Block convolutional layer.
        BasicConvBlockFilters: 32|64|128
        # Pipe-separated string. Kernels for each CNN Block convolutional layer.
        BasicConvBlockKernels: 3|3|3
        # Boolean. Whether to perform max pooling after each standard convolution.
        # Default: True
        BasicConvBlockMaxPool: True
        # Int. Max pool size. Required only if ...MaxPool is True.
        BasicConvBlockMaxPoolSize: 2
        # Int. Max pool strides. Required only if ...MaxPool is True.
        BasicConvBlockMaxPoolStrides: 2
        # Boolean. Whether to perform a final 1x1 convolution. Default: False
        BasicConvBlockBottleneck: False
        # Int. Number of output filters of final 1x1 convolution.
        # Required only if ...Bottleneck is True.
        BasicConvBlockBottleneckFilters: 8
        # Boolean. Whether to include a batch normalization layer after each
        # convolutional layer (including bottleneck). May lead to issues in
        # array-level models. Default: False
        BasicConvBlockBatchNorm: False

        # Model configuration for Basic Fully Connected Head model.
        # Pipe-separated string. Number of units for each FC Head dense layer.
        BasicFCHeadLayers: 1024|512|256|128|64
        # Boolean. Whether to include a batch normalization layer after each
        # dense layer. Default: False
        BasicFCHeadBatchNorm: False

        # Model configuration for Basic Convolutional Head model.
        # Pipe-separated string. Filters for each Conv Head convolutional layer.
        BasicConvHeadFilters: 64|128|256
        # Pipe-separated string. Kernels for each Conv Head convolutional layer.
        BasicConvHeadKernels: 3|3|3
        # Boolean. Whether to perform average pooling over spatial dimensions of 
        # convolutional output before calculating final output. Default: True
        BasicConvHeadAvgPool: True
        # Boolean. Whether to include a batch normalization layer after each
        # convolutional layer. # Default: False
        BasicConvHeadBatchNorm: False

        # The following options (all optional) are used by the provided models.

        # Path to a checkpoint file or model directory from which to
        # load pretrained CNNBlock weights. Default: "" (no weights loaded).
        # Used by: Single Tel, CNN-RNN
        PretrainedWeights: 
        # Float. Used in dropout layers. Default: 0.5
        # Used by: CNN-RNN
        DropoutRate: 0.5
        # Float. Decay parameter for Batch Norm layers. Default: 0.99
        # Used by: Basic (Single Tel)
        BatchNormDecay: 0.99

Training:

    # Required integer.
    # Number of epochs to run training and validation. If 0, run forever.
    num_epochs: 0

    # Required integer.
    # Number of training steps to run before evaluating on the validation set.
    num_training_steps_per_validation: 1000

    Hyperparameters:
        # Required string.
        # Valid options: ['Adadelta', 'Adam', 'RMSProp', 'SGD']
        # Optimizer function for training.
        optimizer: 'Adam'
        
        # Optional float. Required if optimizer is 'Adam', ignored otherwise.
        # Epsilon parameter for the Adam optimizer.
        adam_epsilon: 0.00000001
        
        # Required integer.
        # Base learning rate before scaling or annealing.
        base_learning_rate: 0.001

        # Required Boolean.
        # Whether to scale the learning rate inversely proportional to the
        # number of triggered telescopes. Not used for single tel models.
        scale_learning_rate: false

        # Required Boolean.
        # Whether to weight the loss to rebalance unequal classes.
        apply_class_weights: false

        # Required string or null. If provided, train on only variables
        # within the scope matching this name, freezing all others. This is 
        # useful when loading pretrained weights. If null, train on all
        # trainable variables.
        variables_to_train: null

Prediction:
    # Required Boolean if running in predict mode, ignored otherwise.
    # Whether the data files contain the true classification
    # values. Generally true for simulations and false for actual data.
    true_labels_given: true

    # Optional Boolean. Default: false
    # Whether to export predictions as a CSV file.
    export_as_file: true

    # Required Boolean if running in predict mode and export_as_file is true,
    # ignored otherwise.
    # Path to file to save predictions.
    prediction_file_path: '/tmp/mypredictions.csv'

Debug:
    # Optional Boolean. Default: false
    # Whether to run TensorFlow debugger.
    run_TFDBG: false
