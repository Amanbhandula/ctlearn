[Data]
format = option('HDF5', default='HDF5')
file_list = string(default=None)
apply_processing = boolean(default=True)

    [[Data Loading]]
    selected_tel_types = string_list(default=(list('MSTS'))
    selected_tel_ids = int_list(default=None)
        [[[min_num_tels]]]
            __many__ = integer(min=1, default=1)
        
    cut_condition = string(default="")
    validation_split = float(min=0.0, max=1.0, default=0.1)
    seed = int(default=None)

    [[Data Processing]]
    crop = boolean(default=True)
        [[[bounding_box_sizes]]]
            __many__ = integer(min=1, default=48)

    image_cleaning = option('twolevel', None, default='twolevel') 

        [[[thresholds]]]
            __many__ = float_list(default=list(5.5,1.0))

    return_cleaned_images = boolean(default=False)
    normalization = option('log', None, default=None)
    sort_images_by = option('trigger', 'size', default='trigger')

    [[Data Input]]
    batch_size = integer(min=1, default=64)
    prefetch = boolean(default=True)
    prefetch_buffer_size = integer(min=1, default=10)
    map = boolean(default=False)
    num_parallel_calls = integer(min=1, default=1)
    shuffle = boolean(default=True)
    shuffle_buffer_size = integer(min=1, default=10000)

[Image Mapping]

[Model]
# Required string. Path to directory containing models.
model_directory = string()
# Required string. Module in ModelDirectory containing function implementing
# model. Included, verified modules are "single_tel", "cnn_rnn".
model_module = string(default='cnn_rnn')
# Required string. Function in ModelModule implementing model. Included,
# verified models are "single_tel_model" within the "single_tel" module and
# "cnn_rnn_model" within the "cnn_rnn" module.
model_function = string(default='cnn_rnn_model')
# Required string. Whether the model is for single or multiple telescope
# classification.
model_type = option('single_tel', 'array', default='array')

# optional model parameters
    [[Model Parameters]]
        

[Training]
# Optional int. Number of epochs to run training and validation. If 0, run
# forever. Default: 0
num_epochs = int(min=0, default=0)
# Optional int. Number of training steps to run before evaluating on the 
# training and validation sets. Default: 1000
num_training_steps_per_validation = int(min=1, default=1000)

    [[Hyperparameters]]
    optimizer = option('Adam', 'SGD', 'RMSProp', 'AdaDelta', default='Adam')
    base_learning_rate = float(default=0.001)
    # Optional boolean. Whether to scale the learning rate (for trigger dropout).
    # Not used for single telescope models.
    # Default: False
    scale_learning_rate = boolean(default=False)
    # Optional boolean. Whether to weight the loss to compensate for the class
    # balance. Default: False
    apply_class_weights = boolean(default=False)
    # Optional float. Epsilon parameter for the Adam optimizer. Ignored for other
    # optimizers. Default: 1e-8
    adam_epsilon = float(default=1e-8)
    variables_to_train = string(default=None)

[Prediction]
# Required boolean. Whether the data files contain the true classification
# values. Generally True for simulations and False for actual data.
true_labels_given = boolean(default=None)
# Optional boolean. Whether to export predictions as a file when running in
# predict mode.
export_as_file = boolean(default=None)
# Optional string (required when running in predict mode when ExportAsFile is
# True). Path to file to save predictions.
prediction_file_path = string(default=None)

[Logging]
# Required string. Directory to store TensorFlow model checkpoints and
# summaries. A timestamped copy of the configuration file will be made here.
model_directory = string(default='/tmp/ctalearn/')

[Debug]
# Optional boolean. Whether to run TF debugger. Default: False
run_TFDBG = boolean(default=False)
